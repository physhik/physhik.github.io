<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>generative model on Physics to Data Science</title>
    <link>https://physhik.github.io/tags/generative-model/</link>
    <description>Recent content in generative model on Physics to Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Sep 2017 23:50:00 -0700</lastBuildDate><atom:link href="https://physhik.github.io/tags/generative-model/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Variational Autoencoder</title>
      <link>https://physhik.github.io/2017/09/variational-autoencoder/</link>
      <pubDate>Wed, 20 Sep 2017 23:50:00 -0700</pubDate>
      
      <guid>https://physhik.github.io/2017/09/variational-autoencoder/</guid>
      <description>Mark who I met in machine learning study meetup had recommended me to study a research paper about discrete variational autoencoder. I have read today. As so does variational inference, it includes many mathematical equations, but what the author wants to tell was very straightforward. Two previous posts, Variational Method, Independent Component Analysis, are relevant to the following discussion.
Autoencoder To understand the paper, above all, we need to know what the autoencoder is and what variational autoencoder is.</description>
    </item>
    
    <item>
      <title>Independent Component Analysis and Covariant Learning</title>
      <link>https://physhik.github.io/2017/08/independent-component-analysis-and-covariant-learning/</link>
      <pubDate>Tue, 29 Aug 2017 10:30:00 -0700</pubDate>
      
      <guid>https://physhik.github.io/2017/08/independent-component-analysis-and-covariant-learning/</guid>
      <description>Generative model Generative model is a model for generating all variables including outputs. I will give a very simple example with strong assumptions.
Data $\boldsymbol{x^{(n)} } $ are generated by an unknown matrix, $\boldsymbol{G}$.
$$ \boldsymbol{x} = \boldsymbol{G}~\boldsymbol{s} $$
The goal is to find the source variable $\boldsymbol{s}$.
 we assume that the number of sources is equal to the number of observations We assume that the latent variables are independently distributed, with marginal distributions We assume that the vector $\boldsymbol{x}$ is generated without noise for simplicity.</description>
    </item>
    
  </channel>
</rss>
