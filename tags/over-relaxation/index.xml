<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>over relaxation on Physics to Data Science</title>
    <link>//physhik.com/tags/over-relaxation/</link>
    <description>Recent content in over relaxation on Physics to Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Sep 2017 22:30:00 -0700</lastBuildDate>
    
	<atom:link href="//physhik.com/tags/over-relaxation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MCMC (6): Gibbs Sampling and Overrelaxation</title>
      <link>//physhik.com/2017/09/mcmc-6-gibbs-sampling-and-overrelaxation/</link>
      <pubDate>Fri, 01 Sep 2017 22:30:00 -0700</pubDate>
      
      <guid>//physhik.com/2017/09/mcmc-6-gibbs-sampling-and-overrelaxation/</guid>
      <description>Efficient Monte Carlo sampling 
This post is on the extension of the post about Hamiltonian Monte Carlo method. Therefore, I assume the readers already read the post. Overrelaxation also reduces the random property of the Monte Carlo sampling, and speeds up the convergence of the Markov chain.

Gibbs sampling 
In advance of studying over relaxation, we study Gibbs sampling. In the general case of a system with K variables, a single iteration involves sampling one parameter at a time.</description>
    </item>
    
  </channel>
</rss>