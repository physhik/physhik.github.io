<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>leapfrog algorithm on Physics to Data Science</title>
    <link>//physhik.com/tags/leapfrog-algorithm/</link>
    <description>Recent content in leapfrog algorithm on Physics to Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Sep 2017 16:30:00 -0700</lastBuildDate>
    
	<atom:link href="//physhik.com/tags/leapfrog-algorithm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Neural Network (2) : Inference Using Perceptron and MCMC</title>
      <link>//physhik.com/2017/09/neural-network-2-inference-using-perceptron-and-mcmc/</link>
      <pubDate>Wed, 06 Sep 2017 16:30:00 -0700</pubDate>
      
      <guid>//physhik.com/2017/09/neural-network-2-inference-using-perceptron-and-mcmc/</guid>
      <description>Single neuron still has a lot to say 
In the post of the first neural network tutorial, we studied a perceptron as a simple supervised learning machine. The perceptron is an amazing structure to understanding inference.

In the post of the first neural network tutorial, I said I would leave you to find the objective function and and draw the plot of it. I just introduce here.</description>
    </item>
    
  </channel>
</rss>