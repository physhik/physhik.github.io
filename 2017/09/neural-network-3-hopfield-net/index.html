<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.59.1 with theme Tranquilpeak 0.4.3-SNAPSHOT">
<meta name="author" content="Namshik Kim">
<meta name="keywords" content=", data science, machine learning, neural network">
<meta name="description" content="Binary Hopfield net using Hebbian learning 
We want to study Hopfield net from the simple case. Hopfield net is a fully connected feedback network. A feedback network is a network that is not a feedforward network, and in a feedforward network, all the connections are directed. All the connections in our example will be bi-directed. This symmetric property of the weight is important property of the Hopfield net.">


<meta property="og:description" content="Binary Hopfield net using Hebbian learning 
We want to study Hopfield net from the simple case. Hopfield net is a fully connected feedback network. A feedback network is a network that is not a feedforward network, and in a feedforward network, all the connections are directed. All the connections in our example will be bi-directed. This symmetric property of the weight is important property of the Hopfield net.">
<meta property="og:type" content="article">
<meta property="og:title" content="Neural Network (3) : Hopfield Net">
<meta name="twitter:title" content="Neural Network (3) : Hopfield Net">
<meta property="og:url" content="//physhik.com/2017/09/neural-network-3-hopfield-net/">
<meta property="twitter:url" content="//physhik.com/2017/09/neural-network-3-hopfield-net/">
<meta property="og:site_name" content="Physics to Data Science">
<meta property="og:description" content="Binary Hopfield net using Hebbian learning 
We want to study Hopfield net from the simple case. Hopfield net is a fully connected feedback network. A feedback network is a network that is not a feedforward network, and in a feedforward network, all the connections are directed. All the connections in our example will be bi-directed. This symmetric property of the weight is important property of the Hopfield net.">
<meta name="twitter:description" content="Binary Hopfield net using Hebbian learning 
We want to study Hopfield net from the simple case. Hopfield net is a fully connected feedback network. A feedback network is a network that is not a feedforward network, and in a feedforward network, all the connections are directed. All the connections in our example will be bi-directed. This symmetric property of the weight is important property of the Hopfield net.">
<meta property="og:locale" content="en-us">

  
    <meta property="article:published_time" content="2017-09-10T13:30:00">
  
  
    <meta property="article:modified_time" content="2017-09-10T13:30:00">
  
  
  
    
      <meta property="article:section" content="ML">
    
      <meta property="article:section" content="deep learning">
    
      <meta property="article:section" content="regression">
    
  
  
    
      <meta property="article:tag" content="associative memories">
    
      <meta property="article:tag" content="networkx">
    
      <meta property="article:tag" content="Hopfield net">
    
      <meta property="article:tag" content="Ising model">
    
      <meta property="article:tag" content="Hebbian learning">
    
      <meta property="article:tag" content="U-Net">
    
      <meta property="article:tag" content="regression">
    
  


<meta name="twitter:card" content="summary">







  <meta property="og:image" content="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_22_0.png">
  <meta property="twitter:image" content="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_22_0.png">





  <meta property="og:image" content="/images/avatar.jpg">
  <meta property="twitter:image" content="/images/avatar.jpg">


    <title>Neural Network (3) : Hopfield Net</title>

    <link rel="icon" href="//physhik.com/favicon.ico">
    

    

    <link rel="canonical" href="//physhik.com/2017/09/neural-network-3-hopfield-net/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="//physhik.com/css/style-nnm2spxvve8onlujjlegkkytaehyadd4ksxc1hyzzq9a2wvtrgbljqyulomn.min.css" />
    
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-83159020-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="5">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="//physhik.com/">Physics to Data Science</a>
  </div>
  
    
      <a class="header-right-picture "
         href="//physhik.com/#about">
    
    
    
      
        <img class="header-picture" src="//physhik.com/images/avatar.jpg" alt="Author&#39;s picture" />
      
    
    </a>
  
  <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</header>

      <nav id="sidebar" data-behavior="5">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="//physhik.com/#about">
          <img class="sidebar-profile-picture" src="//physhik.com/images/avatar.jpg" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Namshik Kim</h4>
        
          <h5 class="sidebar-profile-bio">physicist, data scientist</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="//physhik.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="//physhik.com/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="//physhik.com/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="//physhik.com/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="//physhik.com/about/index.html">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/physhik" target="_blank" rel="noopener">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.linkedin.com/in/namshikkim/" target="_blank" rel="noopener">
    
      <i class="sidebar-button-icon fa fa-lg fa-linkedin"></i>
      
      <span class="sidebar-button-desc">LinkedIn</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.researchgate.net/profile/Namshik_Kim" target="_blank" rel="noopener">
    
      <i class="sidebar-button-icon fa fa-lg fa-research-gate"></i>
      
      <span class="sidebar-button-desc">ResearchGate</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="5"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="//schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Neural Network (3) : Hopfield Net
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2017-09-10T13:30:00-07:00">
        
  September 10, 2017

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="//physhik.com/categories/ml">ML</a>, 
    
      <a class="category-link" href="//physhik.com/categories/deep-learning">deep learning</a>, 
    
      <a class="category-link" href="//physhik.com/categories/regression">regression</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              

<p><br></p>

<h2 id="binary-hopfield-net-using-hebbian-learning">Binary Hopfield net using Hebbian learning</h2>

<p><br></p>

<p>We want to study Hopfield net from the simple case. Hopfield net is a fully connected feedback network. A feedback network is a network that is not a feedforward network, and in a feedforward network, all the connections are directed. All the connections in our example will be bi-directed. This symmetric property of the weight is important property of the Hopfield net.</p>

<p><br></p>

<p>Hopfield net can act as associative memories, and they can be used to solve optimization problems. In this post, we will discuss how it behaves as associative memories.</p>

<p><br></p>

<pre><code class="language-python">from __future__ import division
import numpy as np
import random
import matplotlib.pyplot as plt

%matplotlib inline
plt.style.use('ggplot')

</code></pre>

<p><br></p>

<p>Let us call the data<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>, and transform it to an array.</p>

<p><br></p>

<pre><code class="language-python">ch = open('DJCM.txt','r')
for i in ch:
    print i
</code></pre>

<pre><code>1111001001010010100101110

1111100010000101001011100

0111110000100001000001111

1000111011101011000110001

0101010101010101010101010

0111010000011100000101110
</code></pre>

<p><br></p>

<p>Each line consists of 25 binary values (1,0) and each of them will give us a pattern in $5 \times 5$ box. Thus, we have 6 patterns. Will you tell how many neurons are there? We will see the visualized network later, and the neurons will appear as nodes in a graph, and the weights of the connection between neurons will appear as edges of the nodes.</p>

<p><br></p>

<pre><code class="language-python">X = np.zeros((6,25))
</code></pre>

<pre><code class="language-python">ch = open('DJCM.txt','r')
list = []
for i in ch:
    list.append(i)
</code></pre>

<pre><code class="language-python">for i in range(len(list)):
    for j in range(25):
        X[i][j] = int(list[i][j])
</code></pre>

<p><br></p>

<p>Let us change the binary states from (1, 0) to (1, -1).</p>

<p><br></p>

<pre><code class="language-python">X = 2*(X-0.5)
</code></pre>

<p><br></p>

<p>The patterns are encoded in $X$. Display in in $5 \times 5$ box.</p>

<p><br></p>

<pre><code class="language-python">def display(X):
    plt.imshow(X.reshape((5,5)))
</code></pre>

<pre><code class="language-python">fig = plt.figure(figsize=(15,4))
for i in range(6):
    ax = fig.add_subplot(1, 6, i+1)
    display(X[i])
</code></pre>

<p><img src="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_8_0.png" alt="png" /></p>

<p><br></p>

<p>We store the first 4 memories of the patterns in a weight matrix. By Hebb rule,</p>

<p><br></p>

<p>$$
    w_{ij} = \eta \sum_n x^{(n)}_i x^{(n)}_j ,
$$</p>

<p><br></p>

<p>I set $\eta = 1$, and synchronously update the neurons</p>

<p><br></p>

<p>$$
    a_i = \sum_j w_{ij} x_j
$$</p>

<p>then update their states simultaneously to</p>

<p>$$
    x_i = \Theta( a_i ) .
$$</p>

<p><br></p>

<p>$\Theta$ is a threshold activation function, but I would replace it to $\tanh (a_i)$ because it is almost same as the threshold function in this example. The hyper tangent give very close number to 1 and show the same or very similar displays. Above all, more convenient to code to our tests.</p>

<p><br></p>

<pre><code class="language-python">w = np.zeros((25,25))
</code></pre>

<p><br></p>

<pre><code class="language-python">for i in range(25):
    for j in range(25):
        for k in range(4):
            w[i,j] += X[k][i]*X[k][j]
            G.add_edge(i,j, weight = w[i,j])
</code></pre>

<p><br></p>

<h3 id="recovery-of-the-memories">Recovery of the memories</h3>

<p><br></p>

<p>I intentionally ruin the pattern a bit. Recovered by just 1 iteration.</p>

<p><br></p>

<pre><code class="language-python">fig = plt.figure(figsize=(8,4))
fig.add_subplot(1, 2, 1)
testX = X[0]
testX[23] = -testX[23]
display(testX)
fig.add_subplot(1, 2, 2)
a = np.dot(w,testX)
x = np.tanh(a)
display(x)
</code></pre>

<p><img src="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_11_0.png" alt="png" /></p>

<p><br></p>

<h3 id="reaction-to-the-unknown-memories">Reaction to the unknown memories.</h3>

<p><br></p>

<p>Recover it to the deformed memory.</p>

<p><br></p>

<pre><code class="language-python">fig = plt.figure(figsize=(8,4))
fig.add_subplot(1, 3, 1)
display(X[5])
fig.add_subplot(1, 3, 2)
a = np.dot(w,X[5])
x = np.tanh(a)
display(x)
fig.add_subplot(1, 3, 3)
a = np.dot(w,np.dot(w,np.dot(w,np.dot(w,X[5]))))
x = np.tanh(a)
display(x)
</code></pre>

<p><img src="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_12_0.png" alt="png" /></p>

<p><br></p>

<h3 id="oops-my-brain-is-damaged-but-i-can-still-remember">Oops! My brain is damaged! but I can still remember</h3>

<p><br></p>

<p>6 out of 25 weight matrix lost its value, it is 24 percentage-loss. Let us see if it still memorize the 5 memorized patterns.</p>

<p><br></p>

<pre><code class="language-python">dw = w
for i in range(15):
    for j in range(10):
        dw[i+3,j+5] = 0
</code></pre>

<pre><code class="language-python">fig = plt.figure(figsize=(1,4))
for i in range(4):
    ax = fig.add_subplot(1, 4, i+1)
    a = np.dot(dw,X[i])
    x = np.tanh(a)
    display(x)
</code></pre>

<p><img src="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_15_0.png" alt="png" /></p>

<p><br></p>

<p>Amazing! Isn&rsquo;t it?</p>

<p><br></p>

<h3 id="greedy-mommy-made-me-remember-too-many-similar-things">Greedy mommy made me remember too many similar things</h3>

<p><br></p>

<p>If I try to make it memorize all 6 patterns?</p>

<p><br></p>

<pre><code class="language-python">wo = np.zeros((25,25))
for i in range(25):
    for j in range(25):
        for k in range(6):
            wo[i,j] += X[k][i]*X[k][j]
</code></pre>

<pre><code class="language-python">fig = plt.figure(figsize=(8,4))
fig.add_subplot(1, 4, 1)
display(X[0])
fig.add_subplot(1, 4, 2)
a = np.dot(wo,X[0])
x = np.tanh(a)
display(x)
fig.add_subplot(1, 4, 3)
a = np.dot(wo,np.dot(wo,X[0]))
x = np.tanh(a)
display(x)
fig.add_subplot(1, 4, 4)
a = np.dot(wo,np.dot(wo,np.dot(wo,np.dot(wo,X[0]))))
x = np.tanh(a)
display(x)
</code></pre>

<p><img src="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_18_0.png" alt="png" /></p>

<p><br></p>

<p>From the first iteration, it seems that it remembers well, but soon turns out it gets confused if it is true and converges to the wrong answer. This problem can be fixed by better learning algorithm which replace to the Hebbian learning. For example, you can upgrade the Hebb rule using gradient descent we studied for the <a href="//physhik.com/2017/08/neural-network-1-perceptron-and-stochastic-gradient-descent/">perceptron</a>. We will have a chance to discuss about the learning when we study Hopfield net for optimization or Boltzmann machine.</p>

<p><br></p>

<h2 id="visualize-hopfield-net">Visualize Hopfield net</h2>

<p><br></p>

<p>Using the networkx library, we could visualize our network.</p>

<p><br></p>

<h4 id="the-hopfield-net-memorized-4-patterns">The Hopfield net memorized 4 patterns</h4>

<p><br></p>

<pre><code class="language-python">import networkx as nx

G = nx.Graph()

G.add_nodes_from(range(25))
</code></pre>

<pre><code class="language-python">G = nx.Graph()
G.add_nodes_from(range(25))

for i in range(25):
    for j in range(25):
        for k in range(4):
            w[i,j] += X[k][i]*X[k][j]
            G.add_edge(i,j, weight = w[i,j])



nx.draw(G, with_labels =True, font_weight = 'bold')

plt.show()
</code></pre>

<p><img src="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_20_0.png" alt="png" /></p>

<p><br></p>

<p>Apparently, we don&rsquo;t need to connect with zero weights</p>

<p><br></p>

<pre><code class="language-python">G = nx.Graph()
G.add_nodes_from(range(25))

for i in range(25):
    for j in range(25):
        if w[i,j] != 0:
            G.add_edge(i,j, weight = w[i,j])

nx.draw(G, with_labels =True, font_weight = 'bold')
plt.show()
</code></pre>

<p><img src="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_21_0.png" alt="png" /></p>

<p><br></p>

<h3 id="damaged-hopfield-net-and-visualizaion-of-the-weight">Damaged Hopfield net and visualizaion of the weight.</h3>

<p>The damaged Hopfied net has reduced network, but still the network with 24 percentage-loss seems firm. Besides, we can visualize the weight between nodes.</p>

<p><br></p>

<pre><code class="language-python">G = nx.Graph()
G.add_nodes_from(range(25))

for i in range(25):
    for j in range(25):
        if w[i,j] != 0:
            G.add_edge(i,j, weight = dw[i,j])
pos=nx.spring_layout(G)           
labels = nx.get_edge_attributes(G,'weight')
nx.draw_networkx_edge_labels(G,pos,edge_labels=labels)


nx.draw(G, pos, with_labels =True, font_weight = 'bold')



plt.show()
</code></pre>

<p><br></p>

<p>Obviously looks as a feedback network.</p>

<p><br></p>

<p><img src="//physhik.com/images/postimages/HopfieldNetworkx_files/HopfieldNetworkx_22_0.png" alt="png" /></p>

<p><br></p>

<h2 id="the-other-magic-of-the-deep-learning">The other magic of the deep learning</h2>

<p><br></p>

<p>In <a href="//physhik.com/2017/08/neural-network-1-perceptron-and-stochastic-gradient-descent/">the first post of the neural network</a>, I had commented about the magical power of the randomness. Interestingly, the magic was discussed in the meetup for <em>Advanced Reading Data science</em>. The magic we have seen in the associative memory of the neural network was also seen in the meetup this week. What is good to me is their recent interests lie in deep learning. Next week the topic is deep reinforcement learning and I will also post about deep q-learning neural network soon.</p>

<p><br></p>

<p>I was recommended to join the meetup last week. This meetup, <em>Learn Data Science by Doing Kaggle competitions</em>, was also better than my expectation. I thought they would learn some practical library such as <em>pandas</em> or <em>scikit</em>. However, this meetup was more advanced than I thought. It was the meeting to discuss about the core techniques and relevant research papers applied for the competition.</p>

<p><br></p>

<p>The main technique was U-Net. Experienced doctors see the ultrasound film of the neck and they find the irregular such as a tumor. Our goal is to make the machine learn the skill of the experienced doctors. In order to scan the idea of the technique, you can read <a href="https://arxiv.org/abs/1505.04597">this research paper</a> and the references of the paper, or just visit <a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">this website</a> and watch the video on the page.</p>

<p><br></p>

<p>I will not handle the detail of the research paper. Instead, what I want to emphasize on is that making the data more rough works is the key of the technique. When we, human being, read the picture, we don&rsquo;t need to know all of the data. The size of the data human have used to read the ultrasound film should be very little compared to the size of the given data. We need to throw out unnecessary informations to elaborate <em>intuition</em>. The network of the data makes it possible to keep the key structure of the data, and it also improves the speed of the process dramatically.</p>

<p><br></p>

<p><br></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1">If readers want to test it by themselves, save the result of the print as a txt file.
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
</ol>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="//physhik.com/tags/associative-memories/">associative memories</a>

  <a class="tag tag--primary tag--small" href="//physhik.com/tags/networkx/">networkx</a>

  <a class="tag tag--primary tag--small" href="//physhik.com/tags/hopfield-net/">Hopfield net</a>

  <a class="tag tag--primary tag--small" href="//physhik.com/tags/ising-model/">Ising model</a>

  <a class="tag tag--primary tag--small" href="//physhik.com/tags/hebbian-learning/">Hebbian learning</a>

  <a class="tag tag--primary tag--small" href="//physhik.com/tags/u-net/">U-Net</a>

  <a class="tag tag--primary tag--small" href="//physhik.com/tags/regression/">regression</a>

                  </div>
                
              
            
            <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="//physhik.com/2017/09/neural-network-4-deep-reinforcement-learning-q-learning/" data-tooltip="Neural Network (4) : Deep Reinforcement Learning, Q-learning">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="//physhik.com/2017/09/ising-model/" data-tooltip="Ising Model">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 Namshik Kim. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
        <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="//physhik.com/2017/09/neural-network-4-deep-reinforcement-learning-q-learning/" data-tooltip="Neural Network (4) : Deep Reinforcement Learning, Q-learning">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="//physhik.com/2017/09/ising-model/" data-tooltip="Ising Model">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="5">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//physhik.com/images/avatar.jpg" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Namshik Kim</h4>
    
      <div id="about-card-bio">physicist, data scientist</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Vancouver, BC, Canada.
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2019/11/machine-learns-from-cardiologist-4/">
                <h3 class="media-heading">Machine Learns from Cardiologist (4)</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Update 
I had two emails about my ECG classifier Github repo from graduate students after I opened the source code. Please use the issue page of the repo if you have any question or an error of the code.
I myself found some errors due to the version change of Python libraries, so I updated the codes. In the near future, I would update the Python codes suitable for upgraded libraries (won&rsquo;t be posted).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2019/10/new-blog-theme/">
                <h3 class="media-heading">New Blog Theme</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">I decided to use my own domain instead of renting the /github.io/, and also to insert Google adsense in my blog if possible. Even if I updated my blog only 10 times since Oct, 2017, the number of visitors and their sessions were steady by Google analysis. I appreicate the interest on my posts. Recently I started updating my blog again, and want to see the more industrial analytic result. At least I am sure the profit from the adsense will cover the cost for the domain.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2019/03/machine-learns-from-cardiologist-3/">
                <h3 class="media-heading">Machine Learns from Cardiologist (3)</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Open source 
The codes can be found at my Github repo. If you are familar to the models already, just see the codes. The codes are made from understanding of the research papers in Nature and the other and the open source. The host and main contributors of the linked repo are the co-authors of the original research papers. The two related research papers are easy to understand.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2019/03/machine-learns-from-cardiologist-2/">
                <h3 class="media-heading">Machine Learns from Cardiologist (2)</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Understand literatures and the result-analysis 
Deep learning and classifications. 
The pattern recognition using deep convolutional neural network is indisputably good. It shows in various complicated image recognitions or even sound recognition. It is obvious it is going to be so good at least as the similar level of human being.

What matters is if we have enough data, and how we can preprocess the data properly for machine to learn effectively.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2019/03/macnine-learns-from-cardiologist-1/">
                <h3 class="media-heading">Macnine Learns from Cardiologist (1)</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Prologue 
Recenly the interest on wearing device is increasing, and the convolutional neural network (CNN) supervised learning must be one strong tool to analyse the signal of the body and predict the heart disease of our body.

When I scanned a few reseach papers, the 1 dimensional signal and the regular pattern of the heart beat reminds me of musical signals I researched in that it requires a signal process and neural network, and it has much potential to bring healthier life to humar races1, so I want to present the introductory post.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2019/02/youtube-data-api-on-gcp/">
                <h3 class="media-heading">Youtube Data API on GCP</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">To architect low cost and well-performing server, many companies use cloud service such as Amazon AWS, Google clound platform (GCP). I have used AWS EC2 with GPU and S3 storage for my deep learning research at Soundcorset.

AWS and GCP opened many cloud platform services, and to build the data pipeline and to manage the data effectively, need to learn the command line tool and API. In this post, I will discuss the Google Youtube data API because recently I studied.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2019/02/clean-coding-and-short-run-time/">
                <h3 class="media-heading">Clean Coding and Short Run Time</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Today I want to discuss purely about coding itself. I wish this post is helpful for someone want to transit his career from a pure researcher to a programmer. I have been a researcher rather than a programmer. I would just want to execute something to see the result I wanted to see. If the run time is too long or my computer has no enough memory to run the code, it was a sign of new purchase to me.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2018/02/revisited-variational-inference/">
                <h3 class="media-heading">Revisited Variational Inference</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">A few days ago, I was asked what the variational method is, and I found my previous post, Variational Method for Optimization, barely explain some basic of variational method. Thus, I would do it in this post.

Data concerned in machine learning are ruled by physics of informations. It sounds quite abstract, so I will present an example of dynamic mechanics. Let us consider a ball thrown with velocity v=($v_x$, $v_y$) at x = (x, y), and under the vertical gravity with constant g.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2018/02/rough-review-of-wavegan/">
                <h3 class="media-heading">Rough Review of WaveGAN</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Around a week ago, on ArXiv, an interesting research paper appeared, which is about the music style transfer using GAN, which is also my main topic for recent few months. Around a week ago, on arXiv, an interesting research paper appeared, which can be applied to the music style transfer using GAN, which is also my main topic for recent few months. There are already many researches on the style transfer of the images, and one of my main projects now is making the style transfer in music.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="//physhik.com/2017/12/introduction-to-gan/">
                <h3 class="media-heading">Introduction to GAN </h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">I want to introduce some GAN model I have studied after I started working for the digital signal process. I will skip technical detail of the introduction. My goal is to provide a minimal background information.

Revolution in deep learning 
As we have seen at the post of VAE, generative model can be useful in machine learning. Not only one can classify the data but also can generate new data we do not have.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         36 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('//physhik.com/images/cover.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="//physhik.com/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>


<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/\/physhik.com\/2017\/09\/neural-network-3-hopfield-net\/';
          
            this.page.identifier = '\/2017\/09\/neural-network-3-hopfield-net\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'physhiks-data-science';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  


  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      CommonHTML: { linebreaks: { automatic: true } },
      tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
      messageStyle: 'none'
    });
  </script>



    
  </body>
</html>

